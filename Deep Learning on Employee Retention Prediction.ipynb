{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Retention Prediction Using Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 Importing Relevant Libraries\n",
    "- 2 Loading Raw Data\n",
    "- 3 Preprocessing\n",
    "  - 3.1 Handling Categorical Variables\n",
    "- 4 Train Test Split\n",
    "  - 4.1 Data Scaling\n",
    "- 5 Building ANN\n",
    "  - 5.1 Gradient Descent\n",
    "- 6 Select and Train a Model\n",
    "- 7 Apply Model on Test Set\n",
    "  - 7.1 Evaluate Model on Confusion Matrix\n",
    "- 8 Improving the Model\n",
    "  - 8.1 Applying Cross Validation\n",
    "  - 8.2 Adding Dropout Regularization\n",
    "  - 8.3 Applying Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulating\n",
    "import numpy as np  # for data conversion to np array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HR_comma_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years department  \\\n",
       "0                   3              0     1                      0      sales   \n",
       "1                   6              0     1                      0      sales   \n",
       "2                   4              0     1                      0      sales   \n",
       "3                   5              0     1                      0      sales   \n",
       "4                   3              0     1                      0      sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first five records of dataframe\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Handling Categorical Variables\n",
    "\n",
    "Note: The dummy variable trap is a situation whereby two or more variables are highly correlated. This leads to your model performing poorly. \n",
    "\n",
    "Therefore, drop one dummy variable to always remain with N-1 dummy variables. Any of the dummy variables can be dropped because there is no preference as long as you remain with N-1 dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>department_RandD</th>\n",
       "      <th>department_accounting</th>\n",
       "      <th>department_hr</th>\n",
       "      <th>department_management</th>\n",
       "      <th>department_marketing</th>\n",
       "      <th>department_product_mng</th>\n",
       "      <th>department_sales</th>\n",
       "      <th>department_support</th>\n",
       "      <th>department_technical</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  \\\n",
       "0                   3              0     1                      0   \n",
       "1                   6              0     1                      0   \n",
       "2                   4              0     1                      0   \n",
       "3                   5              0     1                      0   \n",
       "4                   3              0     1                      0   \n",
       "\n",
       "   department_RandD  department_accounting  department_hr  \\\n",
       "0                 0                      0              0   \n",
       "1                 0                      0              0   \n",
       "2                 0                      0              0   \n",
       "3                 0                      0              0   \n",
       "4                 0                      0              0   \n",
       "\n",
       "   department_management  department_marketing  department_product_mng  \\\n",
       "0                      0                     0                       0   \n",
       "1                      0                     0                       0   \n",
       "2                      0                     0                       0   \n",
       "3                      0                     0                       0   \n",
       "4                      0                     0                       0   \n",
       "\n",
       "   department_sales  department_support  department_technical  salary_low  \\\n",
       "0                 1                   0                     0           1   \n",
       "1                 1                   0                     0           0   \n",
       "2                 1                   0                     0           0   \n",
       "3                 1                   0                     0           1   \n",
       "4                 1                   0                     0           1   \n",
       "\n",
       "   salary_medium  \n",
       "0              0  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts categorical to numerical variables (dummies)\n",
    "categorical_v = ['department','salary']\n",
    "df_final = pd.get_dummies(df,columns=categorical_v,drop_first=True)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into a training and a testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df_final.drop(['left'],axis=1).values\n",
    "y = df_final['left'].values\n",
    "# deep learning model expects to get the data as arrays\n",
    "# use numpy to convert the data to numpy arrays with the .values attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10499, 18), (4500, 18), (10499,), (4500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% for the training set and 20% for the testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the dataset using StandardScaler\n",
    "# this will ensure a mean of zero and a unit variable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Building ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential # initialize ANN\n",
    "from keras.layers import Dense # add layers to deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a classifier variable\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# adding layers to your network\n",
    "classifier.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter is the number of nodes that the network should have. One of the strategies to determine the number of nodes is to take the average of the nodes in the input layer and the output layer.\n",
    "\n",
    "The second parameter is the `kernel_initializer`. When fit the deep learning model the weights will be initialized to numbers close to zero, but not zero. `kernel_initializer` is the function that initializes the weights.\n",
    "\n",
    "The third parameter is the `activation` function. Deep learning model will learn through this function. There are usually linear and non-linear activation functions. Use the `relu` activation function because it generalizes well on your data.\n",
    "\n",
    "The last parameter is `input_dim`, which represents the number of features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the output layer\n",
    "classifier.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter is the number of output nodes. It is expected to get one output: if an employee leaves the company. Therefore specify one output node.\n",
    "\n",
    "The second parameter is for `kernel_initializer`, use the `sigmoid` activation function to get the probability that an employee will leave. In the event where dealing with more than two categories, use the `softmax` activation function, which is a variant of the `sigmoid` activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Gradient Descent\n",
    "The aim of a gradient descent is to get the point where the error is at its least. This is done by finding where the `cost function` is at its minimum, which is referred to as a local minimum.\n",
    "\n",
    "There are several types of optimization strategies, use the popular one known as `adam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a gradient descent to the neural network\n",
    "classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter `optimizer` is the gradient descent.\n",
    "\n",
    "The second parameter `loss` is a function used in the gradient descent. Since this is a binary classification problem, use the `binary_crossentropy` loss function.\n",
    "\n",
    "The last parameter is the `metric` to evaluate your model. In this case, evaluate is based on its accuracy when making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Select and Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "10499/10499 [==============================] - 4s 363us/step - loss: 0.4352 - acc: 0.7963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1faf961cb70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit classifier to the dataset\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third parameter `batch_size` represents the number of samples that will go through the neural network at each training round.\n",
    "\n",
    "The last paremeter `epochs` represents the number of times that the dataset will be passed via the neural network. The more epochs the longer it will take to run the model, which also gives better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Apply Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the threshold as 50%\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Evaluate Model on Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3334,  106],\n",
       "       [ 679,  381]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy is:  0.9153333333333333\n"
     ]
    }
   ],
   "source": [
    "print ('The model accuracy is: ', (3252+867)/(3252+206+175+867))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Improving the Model\n",
    "In `K-fold crossvalidation`, K is set to 10. The model is trained on the first 9 folds and tested on the last fold. This iteration continues until all folds have been used. The accuracy of the model becomes the average of all these accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def make_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))\n",
    "    classifier.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that will pass to the `KerasClassifier` is a wrapper of the neural network design that was used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the function to the KerasClassifier\n",
    "classifier = KerasClassifier(build_fn = make_classifier, batch_size=10, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter `build_fn` is the function with the neural network design.\n",
    "\n",
    "The second parameter `batch_size` is the number of samples to be passed via the network in each iteration.\n",
    "\n",
    "The third parameter `nb_epoch` is the number of epochs the network will run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Applying Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply CV using Scikit-learn's cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier,X = X_train,y = y_train,cv = 10,n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy is: 0.84275 and the variance is 0.00487\n"
     ]
    }
   ],
   "source": [
    "# compute the mean and variance of the accuracies\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.var()\n",
    "print ('The mean accuracy is:', round(mean,5), 'and the variance is', round(variance,5))\n",
    "# since the variance is very low\n",
    "# it means that the model is performing very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Adding Dropout Regularization\n",
    "In neural networks, `dropout regularization` is the technique that fights overfitting by adding a `Dropout` layer in your neural network. \n",
    "\n",
    "It has a `rate` parameter that indicates the number of neurons that will deactivate at each iteration. The process of deactivating nerurons is usually\n",
    "random. \n",
    "\n",
    "In below, specify 0.1 as the rate meaning that 1% of the neurons will\n",
    "deactivate during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "classifier.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n",
    "classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "# during the training process 15 of the neurons will be deactivated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3 Applying Grid Search\n",
    "`Grid search` is a technique to experiment with different model parameters in order to obtain the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def make_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))\n",
    "    classifier.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer= optimizer,loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = make_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a couple of parameters to experiment\n",
    "params = {\n",
    "'batch_size':[20,35],\n",
    "'epochs':[2,3],\n",
    "'optimizer':['adam','rmsprop']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5249/5249 [==============================] - 1s 239us/step - loss: 0.5867 - acc: 0.7514\n",
      "Epoch 2/2\n",
      "5249/5249 [==============================] - 1s 127us/step - loss: 0.3973 - acc: 0.8209\n",
      "Epoch 1/2\n",
      "5250/5250 [==============================] - 1s 201us/step - loss: 0.5815 - acc: 0.7665\n",
      "Epoch 2/2\n",
      "5250/5250 [==============================] - 1s 131us/step - loss: 0.4038 - acc: 0.8099\n",
      "Epoch 1/2\n",
      "5249/5249 [==============================] - 1s 274us/step - loss: 0.6029 - acc: 0.7584\n",
      "Epoch 2/2\n",
      "5249/5249 [==============================] - 1s 99us/step - loss: 0.4344 - acc: 0.7834\n",
      "Epoch 1/2\n",
      "5250/5250 [==============================] - 1s 225us/step - loss: 0.5844 - acc: 0.7627\n",
      "Epoch 2/2\n",
      "5250/5250 [==============================] - 0s 92us/step - loss: 0.4238 - acc: 0.7888\n",
      "Epoch 1/3\n",
      "5249/5249 [==============================] - 1s 240us/step - loss: 0.5736 - acc: 0.7577\n",
      "Epoch 2/3\n",
      "5249/5249 [==============================] - 1s 98us/step - loss: 0.4098 - acc: 0.7931\n",
      "Epoch 3/3\n",
      "5249/5249 [==============================] - 1s 97us/step - loss: 0.3563 - acc: 0.8253\n",
      "Epoch 1/3\n",
      "5250/5250 [==============================] - 2s 290us/step - loss: 0.5749 - acc: 0.7636\n",
      "Epoch 2/3\n",
      "5250/5250 [==============================] - 1s 104us/step - loss: 0.3822 - acc: 0.8356\n",
      "Epoch 3/3\n",
      "5250/5250 [==============================] - 1s 115us/step - loss: 0.2993 - acc: 0.8937\n",
      "Epoch 1/3\n",
      "5249/5249 [==============================] - 1s 252us/step - loss: 0.5919 - acc: 0.7567\n",
      "Epoch 2/3\n",
      "5249/5249 [==============================] - 1s 121us/step - loss: 0.4415 - acc: 0.7760\n",
      "Epoch 3/3\n",
      "5249/5249 [==============================] - 0s 88us/step - loss: 0.3877 - acc: 0.7920\n",
      "Epoch 1/3\n",
      "5250/5250 [==============================] - 1s 275us/step - loss: 0.6007 - acc: 0.7629\n",
      "Epoch 2/3\n",
      "5250/5250 [==============================] - 1s 111us/step - loss: 0.4492 - acc: 0.7787\n",
      "Epoch 3/3\n",
      "5250/5250 [==============================] - 1s 96us/step - loss: 0.3773 - acc: 0.8130\n",
      "Epoch 1/2\n",
      "5249/5249 [==============================] - 2s 319us/step - loss: 0.6281 - acc: 0.7582\n",
      "Epoch 2/2\n",
      "5249/5249 [==============================] - 0s 55us/step - loss: 0.4716 - acc: 0.7611\n",
      "Epoch 1/2\n",
      "5250/5250 [==============================] - 1s 255us/step - loss: 0.6298 - acc: 0.7606\n",
      "Epoch 2/2\n",
      "5250/5250 [==============================] - 0s 62us/step - loss: 0.4675 - acc: 0.7802\n",
      "Epoch 1/2\n",
      "5249/5249 [==============================] - 2s 341us/step - loss: 0.6350 - acc: 0.7558\n",
      "Epoch 2/2\n",
      "5249/5249 [==============================] - 0s 87us/step - loss: 0.4990 - acc: 0.7579\n",
      "Epoch 1/2\n",
      "5250/5250 [==============================] - 1s 267us/step - loss: 0.6406 - acc: 0.7566\n",
      "Epoch 2/2\n",
      "5250/5250 [==============================] - 0s 77us/step - loss: 0.5102 - acc: 0.7931\n",
      "Epoch 1/3\n",
      "5249/5249 [==============================] - 2s 428us/step - loss: 0.6470 - acc: 0.7400\n",
      "Epoch 2/3\n",
      "5249/5249 [==============================] - 0s 81us/step - loss: 0.4866 - acc: 0.7670\n",
      "Epoch 3/3\n",
      "5249/5249 [==============================] - 0s 76us/step - loss: 0.3911 - acc: 0.8167\n",
      "Epoch 1/3\n",
      "5250/5250 [==============================] - 2s 422us/step - loss: 0.6350 - acc: 0.7589\n",
      "Epoch 2/3\n",
      "5250/5250 [==============================] - 0s 84us/step - loss: 0.4722 - acc: 0.7905\n",
      "Epoch 3/3\n",
      "5250/5250 [==============================] - ETA: 0s - loss: 0.3882 - acc: 0.800 - 1s 103us/step - loss: 0.3856 - acc: 0.8023\n",
      "Epoch 1/3\n",
      "5249/5249 [==============================] - 2s 447us/step - loss: 0.6422 - acc: 0.7523\n",
      "Epoch 2/3\n",
      "5249/5249 [==============================] - 0s 79us/step - loss: 0.5196 - acc: 0.7792\n",
      "Epoch 3/3\n",
      "5249/5249 [==============================] - 0s 71us/step - loss: 0.4295 - acc: 0.7986\n",
      "Epoch 1/3\n",
      "5250/5250 [==============================] - 2s 333us/step - loss: 0.6316 - acc: 0.7621\n",
      "Epoch 2/3\n",
      "5250/5250 [==============================] - 0s 81us/step - loss: 0.4967 - acc: 0.7789\n",
      "Epoch 3/3\n",
      "5250/5250 [==============================] - 0s 86us/step - loss: 0.4058 - acc: 0.8110\n",
      "Epoch 1/3\n",
      "10499/10499 [==============================] - 3s 322us/step - loss: 0.5074 - acc: 0.7733\n",
      "Epoch 2/3\n",
      "10499/10499 [==============================] - 1s 120us/step - loss: 0.3365 - acc: 0.8679\n",
      "Epoch 3/3\n",
      "10499/10499 [==============================] - 1s 109us/step - loss: 0.2815 - acc: 0.8832\n"
     ]
    }
   ],
   "source": [
    "# search for the best parameters\n",
    "grid_search = GridSearchCV(estimator=classifier, \n",
    "                           param_grid=params, scoring=\"accuracy\", cv=2)\n",
    "grid_search = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 20, 'epochs': 3, 'optimizer': 'adam'} 0.8670349557100676\n"
     ]
    }
   ],
   "source": [
    "# obtain the best parameters\n",
    "best_param = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print (best_param, best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built an employee retention model that is able to predict if an employee stays or leaves with an accuracy of up to `86%`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
